{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Explained by StatQuest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Video Link](https://www.youtube.com/watch?v=YCzL96nL7j0&t=71s&ab_channel=StatQuestwithJoshStarmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video explains Long Short-Term Memory (LSTM) networks, a type of recurrent neural network that avoids the exploding/vanishing gradient problem by using separate paths for long-term and short-term memories. It breaks down how LSTM units work using sigmoid and tan-h activation functions to process input data and make predictions.\n",
    "\n",
    "### Highlights\n",
    "- [‚ö°Ô∏è] Long Short-Term Memory (LSTM) networks avoid the exploding/vanishing gradient problem by using separate paths for long-term and short-term memories.\n",
    "- [üß†] LSTM units utilize sigmoid and tan-h activation functions to process input data and make predictions.\n",
    "- [üìä] The video demonstrates how LSTM units can correctly predict future values based on past data by updating long-term and short-term memories through multiple stages.\n",
    "\n",
    "### Keywords\n",
    "- LSTM\n",
    "- Recurrent Neural Networks\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
